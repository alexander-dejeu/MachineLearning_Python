{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>Day 3:  Classifying the Titanic Data Set with Decision Trees</h1></center>\n",
    "\n",
    "In today's exercise, you'll use sklearn's **_DecisionTreeClassifier_** class to predict whether or not a passenger survived the Titanic disaster based on indicators about them.  \n",
    "\n",
    "Also, uh, just in case you haven't seen the movie yet, the Titanic crashes. Spoiler Alert (Apologies to James Cameron).\n",
    "\n",
    "<center><img src=\"titanic.jpg\"></center>\n",
    "\n",
    "You'll be repeating most of the work you did in the Data Camp tutorial as prework for today's class--, but with one major difference.  This time, it's all up to you. Each stage will prompt you with the basic steps for importing, cleaning, exploring, training, and testing--but the implementation of each stage will be up to you.  Remember to use the documentation for pandas, numpy, and sklearn as necessary.  If you don't know how to do something, use the internet to figure it out until you do.  You'll be presenting your model during the start of Thursday's class.\n",
    "\n",
    "\n",
    "\n",
    "<center><h2>Step 1:  Importing and Cleaning the Data</h2></center>\n",
    "\n",
    "The data set is stored in a file in this folder called \"titanic.csv\".  Use pandas to import the data set into a data frame.  Call the data frame whatever you like.  How will you deal with missing values?  Once your data set is \"clean\", remember to split it into a training set and a testing set.  In general, you want to have a 70/30 split between your training and testing sets, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.228956228956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/pandas/core/ops.py:792: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  result = getattr(x, name)(y)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "invalid type comparison",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-0489a8802570>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# print(df)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Embarked\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Pclass\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"S\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Embarked\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Pclass\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"C\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Embarked\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Pclass\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"Q\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, other, axis)\u001b[0m\n\u001b[1;32m    853\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mna_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misscalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m                 raise TypeError('Could not compare %s type with Series' %\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36mna_op\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    792\u001b[0m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 794\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"invalid type comparison\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    795\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: invalid type comparison"
     ]
    }
   ],
   "source": [
    "# Import the Data Set here.  Now, clean your data!  Find missing (NaN) values and deal with them in the manner \n",
    "# you think is most appropriate!\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# df = pd.read_csv?\n",
    "df = pd.read_csv(\"titanic_data_set.csv\")\n",
    "# print(df)\n",
    "row_count = len(df)\n",
    "non_NaN_cabin_rows = df[\"Cabin\"].count()\n",
    "percentage_valid_cabins = non_NaN_cabin_rows / row_count\n",
    "print(percentage_valid_cabins)\n",
    "\n",
    "# Only ~23% of our data has cabin number - which may be relevant, but I think it will be hard to make\n",
    "# inferences if we have less than 25% - Going to drop the column \n",
    "df.drop('Cabin', axis=1, inplace=True)\n",
    "\n",
    "# Also going to drop 'Name' and 'Ticket'\n",
    "df.drop('Name', axis=1, inplace=True)\n",
    "df.drop('Ticket', axis=1, inplace=True)\n",
    "# print(df)\n",
    "# df\n",
    "# df['Sex' == 'female']\n",
    "# print(df[df[\"Sex\"] == \"female\"][\"Age\"].fillna(df[df[\"Sex\"] == \"female\"][\"Age\"].mean()))\n",
    "# print(df[df[\"Sex\"] == \"female\"][df[\"Age\"].isnull()].fillna(df[df[\"Sex\"] == \"female\"][\"Age\"].mean()))\n",
    "# print(df)\n",
    "df['Age'].fillna(df['Age'].mean(), inplace=True)\n",
    "# print(df)\n",
    "\n",
    "df[\"Embarked\"][df[\"Pclass\"] == \"S\"] = 0\n",
    "df[\"Embarked\"][df[\"Pclass\"] == \"C\"] = 1\n",
    "df[\"Embarked\"][df[\"Pclass\"] == \"Q\"] = 2\n",
    "\n",
    "survived = df[\"Survived\"]\n",
    "del df[\"Survived\"]\n",
    "print(df.columns)\n",
    "\n",
    "\n",
    "# Split your data set into training and testing sets. In general, you want to reserve\n",
    "# around 30% of your data for testing.  \n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, survived, test_size = 0.3)\n",
    "print(train)\n",
    "X_train.columns\n",
    "# train_test_split?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h2>Step 2: Exploring the Data</h2></center>\n",
    "\n",
    "Now, you should explore your data.  Get a feel for it using summary statistics, and graphs!  If you're taking this step seriously, you should be graphing a ton of stuff. Some will end up being useful.  Alot of it won't.  Your job here is to discover which features have the strongest correlation with survival outcomes.  This will become important when we start actually training our Decision Tree Classifier!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Explore the data set here.  Try and discover what categories correlate the most with the \n",
    "# survival chance of the passengers!\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(X_train[\"Fare\"][y_train == 1], train['Survived'], train[\"Age\"], s=50, alpha=0.5, c='g')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h2>Step 3: Training a Classifier</h2></center>\n",
    "\n",
    "You've cleaned your data, and split into training and testing sets, and explored your data frame.  Now, on to the fun stuff--let's create and train a Decision Tree Classifier!  Create a Decision Tree Classifier and fit it to your training set.  If you're not sure how, check out the sklearn docs for Decision Tree Classifiers!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create and train a Decision Tree Classifier from sklearn.tree. If you're unsure of how to use the \n",
    "# Decision Tree Classifier, check out the docs for it--sklearn has some of the best documentation out there!\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "target = y_train.values\n",
    "features = X_train[[\"Pclass\", \"Sex\", \"Age\", \"Fare\"]].values\n",
    "\n",
    "my_tree_one = DecisionTreeClassifier().fit(features, target)\n",
    "\n",
    "mode.score(features, traget)\n",
    "\n",
    "# Look at the importance and score of the included features\n",
    "# print(my_tree_one.feature_importances_)\n",
    "# print(my_tree_one.score(\"Age\", \"Survived\"))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h2>Step 4: Evaluating our Model</h2></center>\n",
    "\n",
    "We've trained our model, but **_can we trust our results?_** Use your Decision Tree Classifier to predict the outcomes of the items in your testing set.  Now that we have the results of our testing set predictions, let's calculate our F1 Score to see how we did.  If you aren't sure how to calculate the F1 Score, refer to the docs! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Evaluate your model's accuracy here.  Use your testing set to do--how will you evaluate your model's accuracy?\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "testTarget = y_train.values\n",
    "testFeatures = X_test[[\"Pclass\", \"Sex\", \"Child\", \"Fare\"]].values\n",
    "\n",
    "model.score(testFeatures, testTarget)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h2>Stretch Challenge: Tuning our Model for Higher Accuracy</h2></center>\n",
    "\n",
    "Great job!  Now, tweak your model to see how much higher you can get your accuracy score!  Gloves are off--get that F1 Score up.  Every percentage point counts!\n",
    "\n",
    "(Hint:  Take a look at sklearn's GridSearchCV module!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Stretch challenge--can you tweak your model to get the accuracy up?  How high can you get your accuracy?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
